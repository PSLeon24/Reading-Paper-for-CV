# Reading Paper for Computer Vision(Generative Models, Adversarial Attack)
This repository contains a list of papers I've read while studying Computer Vision during my Master's program.

# Beginner
1. ImageNet Classification with Deep Convolutional Neural Networks
2. Image Super-Resolution Using Deep Convolutional Networks
3. Going deeper with convolutions
4. Deep Residual Learning for Image Recognition

# Intermediate
1. Attention Is All You Need
2. An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale
3. Explaining and Harnessing Adversarial Examples
   - Paper Review: https://psleon.tistory.com/244
   - Seminar: https://github.com/PSLeon24/Reading-Paper-for-CV/blob/main/Seminar/1st/Explaining-and-harnessing-adversarial-examples.pdf
4. Distilling the Knowledge in a Neural Network

# Advanced
1. Learning Transferable Visaul Models From Natural Language Supervision
2. NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis
3. 3D Gaussian Splatting for Real-Time Radiance Field Rendering
4. Efficient Privacy-Preserving Visual Localization Using 3D Ray Clouds
5. Auto-Encoding Variational Bayes : Variational Autoencoder
6. Denoising Diffusion Probabilistic Models
7. Denoising Diffusion Implicit Models
8. High-Resolution Image Synthesis with Latent Diffusion Models
9. Scalable Diffusion Models with Transformers (DiT)
10. GaussianAvatars: Photorealistic Head Avatars with Rigged 3D Gaussians

---

# Adversarial Attack to Defend Against Malicious Deepfake Users
1. How to Backdoor Diffusion Models?
2. Adversarial Backdoor Attack by Naturalistic Data Poisoning on Trajectory Prediction in Autonomous Driving
3. Deep Neural Network are Easily Fooled: High Confidence Predictions for Unrecognizable Images
4. Intriguing Properties of Neural Networks
5. Towards Evaluating the Robustness of Neural Networks
6. How Deep Learning Sees the World: A Survey on Adversarial Attacks & Defenses
7. Are Transformers More Robust Than CNNs?
8. Robust Physical-World Attacks on Deep Learning Visual Classification
9. Disrupting Deepfakes: Adversarial Attacks Against Conditional Image Translation Networks and Facial Manipulation Systems
10. Restricted Black-Box Adversarial Attack Against DeepFake Face Swapping
11. Intriguing Properties of Modern GANs
12. Intriguing properties of synthetic images: from generative adversarial networks to diffusion models
13. Data-free Universal Adversarial Perturbation and Black-box Attack
14. Delving into Transferable Adversarial Examples and Black-box Attacks
15. Knowledge Distillation with Adversarial Samples Supporting Decision Boundary
16. The Limitations of Deep Learning in Adversarial Settings
17. An Efficient Pre-processing Method to Eliminate Adversarial Effects
18. Deflecting Adversarial Attacks with Pixel Deflection
19. Generative Adversarial Perturbations
20. Towards Deep Learning Models Resistant to Adversarial Attacks
21. Disrupting Image-Translation-Based DeepFake Algorithms with Adversarial Attacks
22. Adversarial Example Does Good: Preventing Painting Imitation from Diffusion Models via Adversarial Examples
23. Coexistence of Deepfake Defenses: Addressing the Poisoning Challenge
24. Anti-DreamBooth: Protecting users from personalized text-to-image synthesis
25. SimAC: A Simple Anti-Customization Method for Protecting Face Privacy against Text-to-Image Synthesis of Diffusion Models

# Survey Paper
1. How Deep Learning Sees the World: A survey on Adversarial Attacks & Defenses
2. A Survey on Generative Diffusion Models
